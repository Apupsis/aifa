// @/app/api/api-chat/route.ts

import {
  appendClientMessage,
  appendResponseMessages,
  createDataStream,
  smoothStream,
  streamText,
  generateText,
  DataStreamWriter,
} from "ai";
import { auth } from "@/app/@left/(_public)/(_AUTH)/(_service)/(_actions)/auth";
import {
  type RequestHints,
  systemPrompt,
} from "@/app/@left/(_public)/(_CHAT)/(chat)/(_service)/(_libs)/ai/prompts";
import { getTrailingMessageId } from "@/lib/utils";
import { isProductionEnvironment } from "@/app/@left/(_public)/(_CHAT)/(chat)/(_service)/(_constants)/constants";
import { myProvider } from "@/app/@left/(_public)/(_CHAT)/(chat)/(_service)/(_libs)/ai/providers";
import { entitlementsByUserType } from "@/app/@left/(_public)/(_CHAT)/(chat)/(_service)/(_libs)/ai/entitlements";
import { postRequestBodySchema, type PostRequestBody } from "../chat/schema";
import { geolocation } from "@vercel/functions";
import { NextResponse } from "next/server";
import { prisma } from "@/lib/db";
import { Message, Prisma } from "@prisma/client";
import { generateCuid } from "@/lib/utils/generateCuid";
import { extractSubFromJWT } from "@/lib/utils/extract-sub-from-jwt";

export const maxDuration = 60;

/**
 * Enhanced system prompt for API chat with structured responses
 */
const API_SYSTEM_PROMPT = `
–ü—Ä–æ–¥–æ–ª–∂–∞–π –ª–µ–≥–∫–æ –∏ —É–≤–µ—Ä–µ–Ω—É –±–µ—Å–µ–¥–∞ —Å –∫–ª–∏–µ–Ω—Ç–æ–º, —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –±–ª—é–¥–∞ –∏ –Ω–∞–ø–∏—Ç–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —Ä–∞–Ω–µ–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
`;

// Interface definitions for custom parts
interface ProductPart {
  type: "data-product";
  id: string;
  data: {
    product_id: string;
  };
}

interface SuggestionPart {
  type: "data-suggestion";
  id: string;
  data: {
    suggestion_id: string;
  };
}

/**
 * Analyze text response to determine if product recommendations are needed
 * @param textContent - The assistant's text response
 * @returns Promise with analysis result
 */
async function analyzeForProducts(textContent: string): Promise<{
  recommend_products: boolean;
  category?: string;
  confidence?: number;
}> {
  try {
    const analysisPrompt = `
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–∏ –∫–∞–∫–æ–π –ø—Ä–æ–¥—É–∫—Ç –æ–Ω —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç: "${textContent}"



–ò–∑—É—á–∏ —Ä–∞–Ω–µ–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –º–µ–Ω—é –∏ –Ω–∞–π–¥–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞ –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.

–ï—Å–ª–∏ –ø—Ä–æ–¥—É–∫—Ç—ã –Ω–µ –Ω—É–∂–Ω—ã:
{"recommend_products": false, "confidence": 0.2}

–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
`;

    const result = await generateText({
      model: myProvider.languageModel("api-chat-support"),
      prompt: analysisPrompt,
      temperature: 0.1,
    });

    const analysis = JSON.parse(result.text);
    console.log("üîç Product analysis result:", analysis);
    return analysis;
  } catch (error) {
    console.error("‚ùå Error in product analysis:", error);
    return { recommend_products: false, confidence: 0 };
  }
}

/**
 * Generate contextual suggestions based on assistant's response
 * @param textContent - The assistant's text response
 * @returns Promise with array of suggestions
 */
async function generateSuggestions(textContent: string): Promise<string[]> {
  try {
    const suggestionPrompt = `
–ù–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∫–∞—Ñ–µ —Å–æ–∑–¥–∞–π 2-4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: "${textContent}"

–ì–µ–Ω–µ—Ä–∏—Ä—É–π –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–µ –Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è  –º—è–≥–∫–æ–≥–æ, –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–≥–æ –≤–æ–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ—Ç 1 –¥–æ 6 —Å–ª–æ–≤. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã –∫–æ—Ç–æ—Ä—ã–µ —Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏–¥–µ–∏, –¥–æ–±–∞–≤–ª—è—è –∏–ª–∏ –∏–∑–º–µ–Ω—è—è –∏—Ö.
- –ï—Å–ª–∏ –≥–æ–≤–æ—Ä–∏–ª–∏ –æ –µ–¥–µ: "–•–æ—á—É –∑–∞–∫–∞–∑–∞—Ç—å", "–ß—Ç–æ –µ—â–µ –ø–æ—Å–æ–≤–µ—Ç—É–µ—Ç–µ?", "–ê —á—Ç–æ —Å –Ω–∞–ø–∏—Ç–∫–∞–º–∏?"
- –ï—Å–ª–∏ –æ –Ω–∞–ø–∏—Ç–∫–∞—Ö: "–ë—É–¥—É –±—Ä–∞—Ç—å", "–ü–æ–∫—Ä–µ–ø—á–µ –µ—Å—Ç—å?", "–ê –¥–µ—Å–µ—Ä—Ç –∫ —ç—Ç–æ–º—É?"
- –û–±—â–∏–µ: "–°–ø–∞—Å–∏–±–æ", "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ", "–ù–µ—Ç, —Å–ø–∞—Å–∏–±–æ"

–í–µ—Ä–Ω–∏ JSON –º–∞—Å—Å–∏–≤ –∏–∑ 2-4 –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ—Ä–∞–∑:
["–í–∞—Ä–∏–∞–Ω—Ç 1", "–í–∞—Ä–∏–∞–Ω—Ç 2", "–í–∞—Ä–∏–∞–Ω—Ç 3"]

–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON –º–∞—Å—Å–∏–≤ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
`;

    const result = await generateText({
      model: myProvider.languageModel("api-chat-support"),
      prompt: suggestionPrompt,
      temperature: 0.3,
    });

    const suggestions = JSON.parse(result.text);
    console.log("üí° Generated suggestions:", suggestions);
    return Array.isArray(suggestions) ? suggestions : [];
  } catch (error) {
    console.error("‚ùå Error generating suggestions:", error);
    return ["–°–ø–∞—Å–∏–±–æ", "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ", "–ù–µ—Ç, —Å–ø–∞—Å–∏–±–æ"];
  }
}

/**
 * Get relevant product IDs based on category
 * @param category - Product category
 * @returns Array of product IDs
 */

/**
 * Send product part to data stream
 * @param dataStream - Data stream writer
 * @param productId - Product ID to recommend
 */
function sendProductPart(
  dataStream: DataStreamWriter,
  productId: string
): void {
  const productPart: ProductPart = {
    type: "data-product",
    id: `product-${generateCuid()}`,
    data: {
      product_id: productId,
    },
  };

  console.log("üì¶ Sending product part:", productPart);

  dataStream.writeData({
    type: "data",
    content: JSON.stringify(productPart),
  });
}

/**
 * Send suggestion parts to data stream
 * @param dataStream - Data stream writer
 * @param suggestions - Array of suggestion strings
 */
function sendSuggestionParts(
  dataStream: DataStreamWriter,
  suggestions: string[]
): void {
  suggestions.forEach((suggestion, index) => {
    const suggestionPart: SuggestionPart = {
      type: "data-suggestion",
      id: `suggestion-${generateCuid()}`,
      data: {
        suggestion_id: suggestion,
      },
    };

    console.log(`üí¨ Sending suggestion ${index + 1}:`, suggestionPart);

    dataStream.writeData({
      type: "data",
      content: JSON.stringify(suggestionPart),
    });
  });
}

/**
 * Token usage logging with cost calculation for GPT-4 Mini
 * @param prefix - Prefix for identifying source
 * @param usage - Token usage information object
 * @param chatId - Chat ID for context
 * @param userId - User ID for context
 */
function logTokenUsage(
  prefix: string,
  usage: any,
  chatId?: string,
  userId?: string
) {
  if (!usage) {
    console.log(`${prefix} - –î–∞–Ω–Ω—ã–µ –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã`);
    return;
  }

  const { promptTokens, completionTokens, totalTokens } = usage;

  console.log(`\nüî¢ ===== ${prefix.toUpperCase()} –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –¢–û–ö–ï–ù–û–í =====`);
  console.log(`üìä ID —á–∞—Ç–∞: ${chatId || "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"}`);
  console.log(`üë§ ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: ${userId || "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"}`);
  console.log(`üì• –í—Ö–æ–¥—è—â–∏–µ —Ç–æ–∫–µ–Ω—ã (–ü—Ä–æ–º–ø—Ç): ${promptTokens ?? "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"}`);
  console.log(
    `üì§ –ò—Å—Ö–æ–¥—è—â–∏–µ —Ç–æ–∫–µ–Ω—ã (–û—Ç–≤–µ—Ç): ${completionTokens ?? "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"}`
  );
  console.log(`üîÑ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: ${totalTokens ?? "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"}`);

  // Cost calculation for GPT-4 Mini: Input $0.15/1M, Output $0.60/1M
  if (promptTokens && completionTokens) {
    const inputCost = (promptTokens / 1000000) * 0.15;
    const outputCost = (completionTokens / 1000000) * 0.6;
    const totalCost = inputCost + outputCost;

    console.log(
      `üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å GPT-4 Mini: $${totalCost.toFixed(8)} (–í—Ö–æ–¥: $${inputCost.toFixed(8)}, –í—ã—Ö–æ–¥: $${outputCost.toFixed(8)})`
    );

    const totalCostCents = totalCost * 100;
    console.log(`üí∏ –°—Ç–æ–∏–º–æ—Å—Ç—å –≤ —Ü–µ–Ω—Ç–∞—Ö: ${totalCostCents.toFixed(6)}¬¢`);
  }

  console.log(`‚è∞ –í—Ä–µ–º—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: ${new Date().toISOString()}`);
  console.log(`üî¢ ===== –ö–û–ù–ï–¶ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –¢–û–ö–ï–ù–û–í =====\n`);
}

/**
 * Handle POST requests for creating or adding messages to chats
 * and streaming AI-generated responses with custom parts (three-stage approach)
 */
export async function POST(request: Request) {
  let requestBody: PostRequestBody;
  try {
    const json = await request.json();
    requestBody = postRequestBodySchema.parse(json);
  } catch (e) {
    return new Response("–ù–µ–≤–µ—Ä–Ω–æ–µ —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞", { status: 400 });
  }

  try {
    const {
      id: chatId,
      message,
      selectedChatModel,
      selectedVisibilityType,
    } = requestBody;

    let session = await auth();

    // Handle API token if no session
    let token = request.headers.get("authorization");
    const expires = new Date(Date.now() + 60 * 60 * 4000).toISOString();

    if (!session && token) {
      const sub = extractSubFromJWT(token);
      session = {
        user: {
          id: sub || "",
          type: "apiUser",
        },
        expires,
      };
    }

    if (!session || session.user.id === "") {
      return new Response("–ù–µ–∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω", { status: 401 });
    }

    const userId = session.user.id;
    const userType = session.user.type;

    // Check 24-hour message limit
    const messageCount = await prisma.message.count({
      where: {
        role: "user",
        createdAt: {
          gte: new Date(Date.now() - 24 * 60 * 60 * 1000),
        },
        Chat: {
          userId,
        },
      },
    });

    if (messageCount >= entitlementsByUserType[userType].maxMessagesPerDay) {
      return NextResponse.json(
        {
          error:
            "–í—ã –¥–æ—Å—Ç–∏–≥–ª–∏ –¥–Ω–µ–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤ 5 —Ä–∞–∑ –±–æ–ª—å—à–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–µ–Ω—å!",
          redirectTo: "/register",
          delay: 3000,
        },
        { status: 429 }
      );
    }

    // Check if chat exists
    let chat = await prisma.chat.findUnique({ where: { id: chatId } });

    if (!chat) {
      // Create new chat with title generated from first message
      const title = "Api Chat";
      chat = await prisma.chat.create({
        data: {
          id: chatId,
          userId: userId ? userId : "12345qwert",
          title,
          visibility: selectedVisibilityType,
          createdAt: new Date(),
        },
      });
    } else {
      // Prevent access to other users' chats
      if (chat.userId !== userId) {
        return new Response("–ó–∞–ø—Ä–µ—â–µ–Ω–æ", { status: 403 });
      }
    }

    // Get previous messages ordered by creation time
    const previousMessages = await prisma.message.findMany({
      where: { chatId },
      orderBy: { createdAt: "asc" },
    });

    // Map DB model to AI processing format
    const previousUImessages = previousMessages.map(
      ({ id, role, parts, attachments, createdAt }: Message) => ({
        id,
        role,
        parts,
        experimental_attachments: attachments,
        createdAt,
      })
    );

    // Add new user message to list for AI
    const messages = appendClientMessage({
      // @ts-expect-error: todo add type conversion from DBMessage[] to UIMessage[]
      messages: previousUImessages,
      message,
    });

    // Get geolocation from request for hints
    const { longitude, latitude, city, country } = geolocation(request);
    const requestHints: RequestHints = { longitude, latitude, city, country };

    // Save new user message to DB
    await prisma.message.create({
      data: {
        id: message.id,
        chatId,
        role: "user",
        parts: message.parts,
        attachments: message.experimental_attachments ?? [],
        createdAt: new Date(),
      },
    });

    // Create data stream with three-stage custom parts generation
    const stream = createDataStream({
      execute: async (dataStream) => {
        console.log("üöÄ Starting three-stage response generation...");

        // STAGE 1: Generate basic text response
        const result = streamText({
          model: myProvider.languageModel("api-chat-support"),
          system: API_SYSTEM_PROMPT,
          messages,
          maxSteps: 1,
          experimental_transform: smoothStream({ chunking: "word" }),
          experimental_generateMessageId: generateCuid,
          tools: {}, // No tools - using post-processing approach
          onFinish: async ({ response, usage, text }) => {
            if (!session.user?.id) return;

            // Log token usage for main response
            logTokenUsage("API Chat Main Response", usage, chatId, userId);

            try {
              console.log("üìù Generated text response:", text);

              // STAGE 2: Analyze for product recommendations
              console.log(
                "üîç Stage 2: Analyzing for product recommendations..."
              );
              const productAnalysis = await analyzeForProducts(text);

              if (
                productAnalysis.recommend_products &&
                productAnalysis.category
              ) {
                console.log(
                  `üì¶ Recommending products for category: ${productAnalysis.category}`
                );
              }

              // STAGE 3: Generate contextual suggestions
              console.log("üí° Stage 3: Generating contextual suggestions...");
              const suggestions = await generateSuggestions(text);

              if (suggestions.length > 0) {
                sendSuggestionParts(dataStream, suggestions);
              }

              // Save assistant message to database
              const assistantId = getTrailingMessageId({
                messages: response.messages.filter(
                  (m) => m.role === "assistant"
                ),
              });

              if (!assistantId)
                throw new Error("–°–æ–æ–±—â–µ–Ω–∏–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!");

              const [, assistantMessage] = appendResponseMessages({
                messages: [message],
                responseMessages: response.messages,
              });

              await prisma.message.create({
                data: {
                  id: assistantId,
                  chatId,
                  role: assistantMessage.role,
                  parts: assistantMessage.parts
                    ? JSON.parse(JSON.stringify(assistantMessage.parts))
                    : undefined,
                  attachments: (assistantMessage.experimental_attachments ??
                    []) as unknown as Prisma.InputJsonValue,
                  createdAt: new Date(),
                },
              });

              console.log(
                `‚úÖ –¢—Ä–µ—Ö—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π –æ—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è —á–∞—Ç–∞ ${chatId}`
              );
            } catch (error) {
              console.error("‚ùå –û—à–∏–±–∫–∞ –≤ —Ç—Ä–µ—Ö—Å—Ç—É–ø–µ–Ω—á–∞—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ:", error);
              console.error(
                `‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—à–∏–±–∫–∏ - ID —á–∞—Ç–∞: ${chatId}, ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: ${userId}`
              );
            }
          },
          experimental_telemetry: {
            isEnabled: isProductionEnvironment,
            functionId: "api-stream-text",
          },
        });

        result.consumeStream();
        result.mergeIntoDataStream(dataStream);
      },
      onError: () => "–£–ø—Å, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞!",
    });

    return new Response(stream);
  } catch (error) {
    console.error("POST /api-chat-stream –æ—à–∏–±–∫–∞:", error);
    return new Response("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞!", {
      status: 500,
    });
  }
}
